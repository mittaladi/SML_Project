# -*- coding: utf-8 -*-
"""SML_scratch_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KpfDP5DgYDNzpvB5YKKT83xmHPF2oJc-
"""

from google.colab import drive
drive.mount('/content/gdrive')

cd gdrive/My Drive/Colab/Project

pwd

from PIL import Image
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import glob
import cv2 as cv
import time
import copy as cp
import pandas as pd
import pickle 
import time

import torch
from torch.utils import data
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import torch.optim as optim
import warnings
warnings.filterwarnings("ignore")
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

def load1(path_train,path_test1,path_test2):
    transform = transforms.Compose([transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
    batch_size=32
    
    trainloader = torch.utils.data.DataLoader(
          ImageFilelist(root=path_train,lbl='Training', 
          transform=transform),
          batch_size=batch_size, shuffle=True, pin_memory=True)
    
    testloader1 = torch.utils.data.DataLoader(
          ImageFilelist(root=path_test1,lbl='PublicTest',
          transform=transform),
          batch_size=batch_size, shuffle=True, pin_memory=True)

    testloader2 = torch.utils.data.DataLoader(
          ImageFilelist(root=path_test2,lbl='PrivateTest',
          transform=transform),
          batch_size=batch_size, shuffle=True, pin_memory=True)

          
    return trainloader,testloader1,testloader2

def train(trainloader,net):
    trn=[]; lbl=[]; c=0; t=time.time()
    with torch.no_grad():
         for data1 in trainloader:
             c+=1
             if(c%100==0):
                 print('Training: ',c,', Time: ',time.time()-t)
                 t=time.time()
             images, labels = data1
             images, labels = torch.tensor(images), torch.tensor(labels)
             images, labels = images.to(device), labels.to(device)
             out = net(images)
             for outputs in out:
                trn.append(cp.deepcopy(np.array(outputs.cpu(),np.double)))
             for label in labels:
                lbl.append(cp.deepcopy(np.array(label.cpu(),np.int32)))
    return np.array(trn),np.array(lbl)
         
    
def test(testloader,net):
    tst=[]; lbl=[]; c=0; t=time.time()
    with torch.no_grad():
         for data1 in testloader:
             c+=1
             if(c%50==0):
                 print('Testing: ',c,', Time: ',time.time()-t)
                 t=time.time()
             images, labels = data1
             images, labels = torch.tensor(images), torch.tensor(labels)
             images, labels = images.to(device), labels.to(device)
             out = net(images)
             for outputs in out:  
                tst.append(cp.deepcopy(np.array(outputs.cpu(),np.double)))
             for label in labels:
               lbl.append(cp.deepcopy(np.array(label.cpu(),np.int32)))
    return np.array(tst),np.array(lbl)

def default_flist_reader(flist,lbl):
    imlist=[]
    path='fer2013.csv'
    data=pd.read_csv(path)
    emotion={0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Sad', 5:'Surprise', 6:'Neutral'}
    for i in range(len(data.pixels)):
        if(lbl==data.Usage[i]):
          im=np.array(data.pixels[i].split(' '),np.uint8)
          im.shape=(48,48)
          im=Image.fromarray(im).convert('RGB')
          nm=data.emotion[i]
          imlist.append(cp.deepcopy((im,nm)))    
    print(len(imlist))
    return imlist
   
class ImageFilelist(data.Dataset):
     def __init__(self, root, transform=None,lbl='Training', target_transform=None,
         flist_reader=default_flist_reader):
         self.lbl=lbl
         self.imlist = flist_reader(root,lbl)
         self.transform = transform
         self.target_transform = target_transform
         
   
     def __getitem__(self, index):
         img, target = self.imlist[index]
         #img = self.loader(impath)
         if self.transform is not None:
            img = self.transform(img)
         if self.target_transform is not None:
            target = self.target_transform(target)
         return img, target
   
     def __len__(self):
         return len(self.imlist)

p_trn='/Training/'
p_tst1='/PublicTest/'
p_tst2='/PrivateTest/'
trainloader,testloader1,testloader2=load1(p_trn,p_tst1,p_tst2)

def test(testloader):
  correct = 0
  total = 0
  #L=[]; P=[]
  with torch.no_grad():
    for data in testloader:
        images, labels = data
        images, labels=images.to(device), labels.to(device)
        outputs = net(images)
        #for i in labels:
        #  L.append(numpy.array(i.cpu()))
        _, predicted = torch.max(outputs.data, 1)
        #for i in predicted:
        #   P.append(numpy.array(i.cpu()))
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
  
  return 100 * (correct / total)

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 3)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 8, 5)
        self.conv3 = nn.Conv2d(8, 12, 7)
        self.conv4 = nn.Conv2d(12, 16, 3)
        self.conv5 = nn.Conv2d(16, 32, 5)
        self.conv6 = nn.Conv2d(32, 64, 7)
        self.fc1 = nn.Linear(7*7*64, 800)
        self.fc2 = nn.Linear(800, 140)
        self.fc3 = nn.Linear(140, 7)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        x = F.relu(self.conv3(x))
        x = self.pool(F.relu(self.conv4(x)))
        x = F.relu(self.conv5(x))
        x = F.relu(self.conv6(x))
        x = x.view(-1,64*7*7)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


net = Net()
net.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

x=[]; y1=[]; y2=[]; er=[]
for epoch in range(1000):  
    running_loss = 0.0
    counter=0
    for i, data in enumerate(trainloader, 0):
        counter+=1
        inputs, labels = data
        inputs, labels =inputs.to(device), labels.to(device) 
        optimizer.zero_grad()

        outputs = net(inputs)
        #print(outputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()    
    acc_pub=test(testloader1)
    acc_pri=test(testloader2)
    print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss),' | Accuracy--  val: %0.2f'%(acc_pub),' | test: %0.2f'%(acc_pri))
    y1.append(acc_pub)
    y2.append(acc_pri)
    x.append(epoch)
    er.append(running_loss)
    if(epoch % 25 ==0):
      torch.save({
            'epoch': epoch,
            'model_state_dict': net.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': running_loss,
            }, '/hello')

plt.plot(x,y1,label='validation acccuracy')
plt.plot(x,y2,label='testing accuracy')
plt.xlabel('epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training Error plot')

plt.plot(x,er)
plt.xlabel('epouch')
plt.ylabel('Cross Entropy Loss')

torch.save(net,'/hello')

import pickle
with open("net9_1.pickle", "wb") as output_file:
     pickle.dump(net, output_file)



pwd

torch.save({
            'epoch': epoch,
            'model_state_dict': net.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': running_loss,
            }, '/hello')

"""**References**"""

[1] https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html
[2] https://pytorch.org/docs/stable/torchvision/models.html
[3] https://pytorch.org/docs/stable/data.html
[4] https://github.com/pytorch/vision/issues/81